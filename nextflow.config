manifest {
  description = 'Synteny analysis' 
  author = 'Chris Wyatt and Simon Murray'
}

// Defaults parameters, expecting to be overwritten
params {
  // Path to results directory
  outdir                     = "results"
  // Path to input CSV
  input                      = null
  hex                        = "s3://synteny-test-data/data/unique_hex"
  go                         = null
  tree                       = null
  ribbon                     = null
  score                      = null
  chromopaint                = true
  lifted                     = true
  // Remove work directories upon pipeline completion
  clean                      = true
  // Architecture of platform pipeline is running on
  architecture               = "amd"
  // include basic config
  custom_config              = null
  // Max resource options
  max_memory                 = '128.GB'
  max_cpus                   =  16
  max_time                   = '48.h'
  // Display help message with nf-validation
  help = null
  // nf-core module parameters
  publish_dir_mode           = 'copy'
  params.seqkit_basename     = null
  params.seqkit_fq_encoding  = null
  params.seqkit_gap_letters  = null
}

plugins {
  id 'nf-co2footprint@1.0.0-beta'
  id 'nf-schema@2.0.0'
  id 'nf-amazon@2.5.2'
}

def timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')

co2footprint {
    traceFile   = "${params.outdir}/pipeline_info/co2_emissions/co2footprint_trace_${timestamp}.txt"
    reportFile  = "${params.outdir}/pipeline_info/co2_emissions/co2footprint_report_${timestamp}.html"
    summaryFile  = "${params.outdir}/pipeline_info/co2_emissions/co2footprint_summary_${timestamp}.html"
    ci          = 300
    pue         = 1.4
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load custom config if provided
if (params.custom_config != null) {
   try {
       includeConfig "${params.custom_config}"
    } catch (Exception e) {
       System.err.println("WARNING: Could not load config: ${params.custom_config}")
   }
}

// Select a combination of useful profiles i.e. nextflow run -profile local,docker 
profiles {
  local {
    executor.name            = 'local'
  }
  aws_batch {
    includeConfig 'conf/aws_batch.config'
  }
  //Use Docker as the container management software
  docker {
    docker.enabled           = true
    // Remove docker containers after pipeline completes
    docker.remove            = true
    // Sets user for docker to the user who executes pipeline
    docker.runOptions        = '-u $(id -u):$(id -g)'
    // set registry to quay.io
    docker.registry          = "quay.io"
    // Ensure other container engines are unset
    singularity.enabled      = false
    apptainer.enabled        = false
  }
  singularity {
    singularity.enabled      = true
    // Set where singularity cached images are saved
    singularity.cacheDir     = "singularity/cachedir"
    // set registry to quay.io
    singularity.registry     = "quay.io"
    // Ensure other container engines are unset
    docker.enabled           = false
    apptainer.enabled        = false
  }
  apptainer {
    apptainer.enabled        = true
    // Set where singularity cached images are saved
    apptainer.cacheDir       = "apptainer/cachedir"
    // set registry to quay.io
    apptainer.registry       = "quay.io"
    // Ensure other container engines are unset
    docker.enabled           = false
    singularity.enabled      = false
  }
  test { includeConfig 'conf/test.config'       }
}

// Load nf-core modules config
includeConfig 'conf/modules.config'

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Capturing Nextflow log files into a rsults/pipeline_info directory
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${timestamp}.html"
}

// Ensures work directories and removed when pipeline completes
if (params.clean == true) {
   cleanup = true
}

// Function to ensure that resource requirements don't go beyond a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
